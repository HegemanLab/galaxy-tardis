#!/bin/bash
# setup_env.example: Set up environment variable files for restoration example.
#   Adjust or replace any or all environment variables as appropriate to your case.

# source second argument if provided, e.g., 'globals.custom'
if [ ! -z "$1" ]; then
  . "$1"
fi

# Set DEMO_RUN_MODE to "restore" when you want DEMO to restore from S3-compatible buckets
# Set DEMO_RUN_MODE to "fresh" when you want DEMO to cleanly install Galaxy if it has not already been installed
# Set DEMO_RUN_MODE to "run" when you want DEMO to run without initialization attempts
DEMO_RUN_MODE=${DEMO_RUN_MODE:-run}

# Name you will use for your Galaxy instance
#  Currently only used by 'screen' and in this file, but you use it as you want
MY_INSTANCE=${MY_INSTANCE:-myinstance}

# This example assumes that S3 buckets are named like this:
#   myprefix-myinstance.config
#   myprefix-myinstance.datasets
# that hold Galaxy config and Galaxy datasets, respectively
# Prefix for bucket names - again, feel free to change it
MY_BUCKET_PREFIX=${MY_BUCKET_PREFIX:-myprefix}

# Conda base's python version: should be '2' or '3'; default is '3'
MY_GALAXY_TOOL_DEPS_CONDA_BASE_PYTHON_VERSION=${MY_GALAXY_TOOL_DEPS_CONDA_BASE_PYTHON_VERSION:-3}

# Note: This example REQUIRES that the directory used to persist your Galaxy
#   data exists BEFORE you run docker-compose
# For the expected layout, please see:
#   https://github.com/bgruening/docker-galaxy-stable/tree/master/compose#configuration--4
# Specify the fully nonsymbolic path on docker host to directory that will be
#   mounted as '/export' in container (replace '/path/to/export' with the actual
#   path to an existing directory that the user owns).
MY_GALAXY_EXPORT=${MY_GALAXY_EXPORT:-`readlink -f /path/to/export`}

# Set MY_USERNETES to the path on docker host where usernetes is located, if you are using usernetes,
#   e.g., an unzipped release from https://github.com/rootless-containers/usernetes/releases
#   Running without Usernetes is not yet supported.  Hopefully it will be soon.
MY_USERNETES=${MY_USERNETES:-~/usernetes}

# S3 configuration:
# Set MY_S3CFG to the path to the config file created by
#   s3cmd --config
# This is were you will specify the location where your S3 buckets are stored.
# See https://github.com/s3tools/s3cmd for further info
MY_S3CFG=${MY_S3CFG:-./tardis/s3/dest.s3cfg}
# Set MY_CONFIG_BUCKET to the name of configuration-backup bucket on S3-compatible storage;
#   This bucket stores backups of evertying except datasets.
MY_CONFIG_BUCKET=${MY_CONFIG_BUCKET:-${MY_BUCKET_PREFIX}-${MY_INSTANCE}.config}
# Set MY_DATASET_BUCKET to the name of dataset-storage bucket on S3-compatible storage.
#   If you are using an S3 or SWIFT object store for Galaxy, use the name of that bucket here
MY_DATASET_BUCKET=${MY_DATASET_BUCKET:-${MY_BUCKET_PREFIX}-${MY_INSTANCE}.datasets}

# Specify which docker-compose file to use, probably this is fine
MY_COMPOSE_FILE=${MY_COMPOSE_FILE:-docker-compose-env.yml}

# Specify the path used inside containers that will persist Galaxy data in Docker, probably '/export'
INTERNAL_EXPORT_DIR=${INTERNAL_EXPORT_DIR:-'/export'}
# Specify the path on docker host to the directory that will be mounted as '/export' in container
EXPORT_DIR=${MY_GALAXY_EXPORT:?}

# Specify the parent directory for the PostgreSQL database files to be stored;
#   the database files will be init'ed in subdirectory '$PGDATA_SUBDIR'
# You must change '/path/to/postgres' to a real path to a directory that you own.
PGDATA_PARENT=${MY_GALAXY_POSTGRES:-`readlink -f /path/to/postgres`}
# Sorry about this. Some of my scripts use the name MY_GALAXY_POSTGRES instead.
MY_GALAXY_POSTGRES=${PGDATA_PARENT:?}
# Name of subdirectory of PGDATA_PARENT for PostgreSQL database
#   will be renamed (to save it) and replaced during restoration.
#   You probably don't need to chnage this
PGDATA_SUBDIR=${PGDATA_SUBDIR:-main}

# Specify the docker image name for PostgreSQL executables
IMAGE_POSTGRES=${IMAGE_POSTGRES:-'quay.io/bgruening/galaxy-postgres'}
# Specify the tag for the docker image for PostgreSQL executables
TAG_POSTGRES=${TAG_POSTGRES:-9.6.5_for_19.01}

# Docker image name for Galaxy initialization executables
# N.B. that initialization of the Galaxy '/export' may change in the future,
#      but this works for the containers for 19.01
IMAGE_GALAXY_INIT=${IMAGE_GALAXY_INIT:-'quay.io/bgruening/galaxy-init'}
# Docker image tag for Galaxy initialization executables
TAG_GALAXY=${TAG_GALAXY:-'19.01'}
# Name of Galaxy initialization container
CONTAINER_GALAXY_INIT=${CONTAINER_GALAXY_INIT:-'galaxy-init'}

# Tag for the proftpd image - presently the image name is hard-coded in docker-compose-env.yml
TAG_PROFTPD=${TAG_PROFTPD:-for_galaxy_19.01}

# Default tag for containers; the image names are hard-coded in docker-compose-env.yml
TAG_DEFAULT=${TAG_DEFAULT:-"$TAG_GALAXY"}

# Postgres password - If the postgres listener is not exposed outside docker
#    containers, there should be little risk in exposing the password here.
POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-chaopagoosaequuashie}

# This specifies the port where the Galaxy web server will listen
GALAXY_PORT=${GALAXY_PORT:-8080}

# Ports to forward outside the "rootless namespace";
#   you won't need these if you are running Docker as root
# For explanation, see https://github.com/rootless-containers/rootlesskit#port-drivers
NET_ADD=${NET_ADD:-"
0.0.0.0:8080:${GALAXY_PORT}/tcp
0.0.0.0:5050:5050/tcp
"}
NET_REMOVE=${NET_REMOVE:-"
/${GALAXY_PORT}/{ s/[^0-9].*//; p }
/5050/{ s/[^0-9].*//; p }
"}

# This is the compose file to run (in this directory)
COMPOSE_FILE=${MY_COMPOSE_FILE:?}

# These are the containers in the compose file that we intend to run.
#   Add or remove a needed, e.g., to run HT-Condor
CONTAINERS_TO_RUN=${CONTAINERS_TO_RUN:-'galaxy-postgres galaxy-slurm galaxy-web galaxy-proftpd rabbitmq galaxy-init grafana pgadmin4'}

# Now generate the environment files:
source setup_env.in
